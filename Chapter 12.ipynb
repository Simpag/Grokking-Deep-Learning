{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, random, math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "f = open('tasksv11/en/qa1_single-supporting-fact_train.txt', 'r')\n",
    "raw = f.readlines()\n",
    "f.close()\n",
    "\n",
    "tokens = list()\n",
    "for line in raw[0:1000]:\n",
    "    tokens.append(line.lower().replace('\\n', '').split(' ')[1:])\n",
    "    \n",
    "vocab = set()\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        vocab.add(word)\n",
    "        \n",
    "vocab = list(vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x_):\n",
    "    x = np.atleast_2d(x_)\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "def words2indices(sentence):\n",
    "    idx = list()\n",
    "    for word in sentence:\n",
    "        idx.append(word2index[word])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "embed_size = 10\n",
    "\n",
    "embed = (np.random.rand(len(vocab), embed_size) - 0.5) * 0.1\n",
    "\n",
    "recurrent = np.eye(embed_size)\n",
    "\n",
    "start = np.zeros(embed_size)\n",
    "\n",
    "decoder = (np.random.rand(embed_size, len(vocab)) - 0.5) * 0.1 # output weights\n",
    "\n",
    "one_hot = np.eye(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop ---old---\n",
    "alpha = 0.01\n",
    "y = np.array([1,0,0,0,0,0,0,0,0])\n",
    "\n",
    "pred_delta = pred - y\n",
    "\n",
    "layer_2_delta = pred_delta.dot(sent2output.T)\n",
    "defeat_delta = layer_2_delta * 1\n",
    "\n",
    "layer_1_delta = layer_2_delta.dot(identity.T)\n",
    "sox_delta = layer_1_delta * 1\n",
    "\n",
    "layer_0_delta = layer_1_delta.dot(identity.T)\n",
    "\n",
    "word_vects['red']    -= alpha * layer_0_delta\n",
    "word_vects['sox']    -= alpha * sox_delta\n",
    "word_vects['defeat'] -= alpha * defeat_delta\n",
    "\n",
    "identity    -= alpha * np.outer(layer_0, layer_1_delta)\n",
    "identity    -= alpha * np.outer(layer_1, layer_2_delta)\n",
    "sent2output -= alpha * np.outer(layer_2, pred_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
